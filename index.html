<!DOCTYPE html>
<html lang="en">

<head>
	<!-- Title -->
	<title>Yihang Yao
    </title>

	<!-- Required meta tags -->
	<meta charset="utf-8">
	<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

	<!-- Bootstrap core CSS -->
	<link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0/css/bootstrap.min.css" >
	<!-- integrity="sha384-Gn5384xqQ1aoWXA+058RXPxPg6fy4IWvTNh0E263XmFcJlSAwiGgFAW/dAiS6JXm" crossorigin="anonymous"> -->
	<!-- https://fontawesome.com/cheatsheet -->
	<link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.3.1/css/all.css" integrity="sha384-mzrmE5qonljUremFsqc01SB46JvROS7bZs3IO2EmfFsd15uHvIt+Y8vEf7N7fWAU" crossorigin="anonymous">
	<link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons/css/academicons.min.css">
    <link rel="stylesheet" href="static/styles.css">

    <!-- Scripts -->
    <script type="text/javascript" src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script>
	<script src="./main.js"></script>
  	<script src="./scroll.js"></script>

	<!-- Randomly select profile pics -->
	<script src="./rand_pics.js" type="text/javascript"></script>

	<!-- Show more content -->
	<script type="text/javascript">
		function toggle_vis(id) {
	    	// var e = document.getElementById(id);
	    	var e = document.getElementsByClassName(id);
			var showText = document.getElementById("showText");
			for (var i = 0; i < e.length; i++) {
		    	if (e[i].style.display == "none") {
		        	e[i].style.display = "inline";
	    			showText.innerHTML = "[Show less]";
		    	} else {
		    		e[i].style.display = "none";
		    		showText.innerHTML = "[Show more]";
		    	}
		    }
	    }
	</script>

	<!-- Custom br space -->
	<style type="text/css">
        .brsmall {
            display: block;
            margin-bottom: 0.75em;
        }
        .brmedium {
            display: block;
            margin-bottom: 1em;
        }
    </style>
</head>


<body>
	<!-- <nav class="navbar navbar-expand-md navbar-dark fixed-top bg-dark">
	    <div class="container">
			<a class="navbar-brand" href="#">Zhepeng Cen</a>

			<button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarToggle">
		  		<span class="navbar-toggler-icon"></span>
			</button>

			<div class="collapse navbar-collapse" id="navbarToggle">
				<ul class="navbar-nav ml-auto">
					<li class="nav-item">
						<a class="nav-link" href="#">Home</a>
					</li>
					<li class="nav-item">
						<a class="nav-link" href="#Publications">Publications</a>
					</li>
				</ul>
			</div>
		</div>
	</nav> -->

	<div class="container" style="padding-top: 0px">
		<div class="row">
			<div class="col-md-3", style="padding-top: 35px">
				<p style="text-align: center;">
					<img class="img-responsive img-rounded" src="static/Yihang-GPT4o.png" alt="" style="max-width: 200px; border:2px solid gray;">
				</p>
				<!-- <script>onLoadImg();</script> -->

				<p style="font-size: 14px; text-align: center;">
					<a target="_blank" href="https://scholar.google.com/citations?user=EPduTdwAAAAJ&hl=en&oi=ao"> Google Scholar </a> / 
					<a target="_blank" href="https://www.linkedin.com/in/yihang-yao-3a7658249/"> LinkedIn </a>
					<!-- <a target="_blank" href="https://drive.google.com/file/d/1cb2poyWisjMuYYwWNh5Xu3cn0a2UzTSG/view?usp=sharing"> CV (2024 Sep) </a> -->
					<!-- <a target="_blank" href="https://www.linkedin.com/in/zhepeng-cen/"><font color="black"><i class="fab fa-linkedin fa-lg"></i></font></a> -->
				</p>
			</div>
			<div class="col-md-9", style="padding-top: 35px">
				<p style="font-size: 30px">
					Yihang Yao
				</p>
				<p style="padding-top: 0px"><tt>yihangya[at]andrew.cmu.edu</tt></p>

				<p>
					Hi, welcome to my website! I am a third-year Ph.D. candidate in <a target="_blank" href="https://safeai-lab.github.io/">Safe AI Lab</a> at Carnegie Mellon University, advised by Prof. Ding Zhao. 
					I work on Language Model and Reinforcement Learning.	
				</p>
						<p>	
					Before CMU, I received my Bachelor's degree from Shanghai Jiao Tong University in 2022. In 2021, I spent a wonderful time working as a research intern in the <a target="_blank" href="http://icontrol.ri.cmu.edu/">Intelligent Control Lab</a> led by Prof. Changliu Liu at CMU.
				</p>
				<p></p>
				<!-- My research topic focuses on reinforcement learning and its application for decisition-making. Currently, I am interested in data-centric approaches for learning systems. -->
				</p>
			</div>
		</div>
	</div>
	<span class="brmedium"></span>


	<!-- News -->
	<div class="container">
		<h5 id="News" style="padding-top: 75px; margin-top: -75px;">News</h5>

		<ul>
			<li>
				<span class="title">[2025/05]</span> Listed as a notable reviewer for ICLR 2025.
			</li>
			<li>
				<span class="title">[2025/05]</span> Two papers are accepted by the findings of ACL 2025.
			</li>
			<li>
				<span class="title">[2024/09]</span> One paper is accepted by NeurIPS 2024.
			</li>
			<!-- <li>
				<span class="title">[2024/09]</span> Invited talk about offline and safe RL at UIUC Human-Centered Autonomy Lab.
			</li> -->
			<li>
				<span class="title">[2024/06]</span> One paper is accepted by DMLR.
			</li>
			<li>
				<span class="title">[2024/05]</span> One paper is accepted by ICML 2024.
			</li>
			<li>
				<span class="title">[2024/03]</span> One paper is accepted by L4DC 2024.
			</li>
			<li>
				<span class="title">[2024/01]</span> One paper is accepted by ICLR 2024.
			</li>
			<li>
				<span class="title">[2023/09]</span> One paper is accepted by NeurIPS 2023.
			</li>
			<li>
				<span class="title">[2023/05]</span> Two papers are accepted by ICML 2023.
			</li>
		</ul>

		<br>
	</div>


	<!-- Publications -->
	<div class="container">
		<h5 id="Publications" style="padding-top: 75px; margin-top: -75px;">  <!-- style="margin-bottom: 0.1em" -->
			<!-- Publications <small><small>&nbsp;<a target="_blank" href="https://scholar.google.com/citations?user=0_bSbIoAAAAJ&hl=en">[Full List]</a></small></small> -->
			Selected Works
			<!-- <small>&nbsp; (
				<a href="" id="select0" onclick="showPubs(0); return false;">show selected</a> /
				<a href="" id="select1" onclick="showPubs(1); return false;">show by date</a>
				)
			</small> -->
		</h5>
		<div>
			<small><span class="author">(* indicates equal contribution)</span></small>
		</div>

		<div class="row">
			<div id="MEND" class="col-md-3">
				<a>
					<img class="img-responsive" src="./static/publication/BRIDGE2.png" width="220px" height="230px" style="padding-top:30px; padding-left:35px">
				</a>
			</div>
			<div class="col-md-9" style="padding-top:30px">  
				<h5><font color="#000000"><div style="line-height:20px; font-size:18px;">Behavior Injection: Preparing Language Models for Reinforcement Learning</div></font></h5>
				<p style="line-height:20px;font-size:14px;">
					Zhepeng Cen*, <span style="color: #000000"><strong>Yihang Yao</strong></span>*,  
					William Han, 
					Zuxin Liu, Ding Zhao
				</p> 
				<p style="line-height:10px;font-size:14px;color: #000000">
					2025 
				</p> 
				<p style="line-height:20px;font-size:14px;color: #777777">
					TL;DR: This paper proposes behavior injection, a meta-RL approach that augments SFT data with exploratory and exploitative behaviors to help language models better adapt during reinforcement fine-tuning.
				<p style="line-height:10px;font-size:14px;color: #777777">
					<a href="https://arxiv.org/abs/2505.18917" target="_blank">Paper</a> /
					<a href="https://github.com/czp16/Bridge-LLM-reasoning" target="_blank">Code</a> 
				</p> 
				
			</div>
		</div>

		<div class="row">
			<div id="MEND" class="col-md-3">
				<a>
					<img class="img-responsive" src="./static/publication/MEND.png" width="250px" height="145px" style="padding-top:30px">
				</a>
			</div>
			<div class="col-md-9" style="padding-top:30px">  
				<h5><font color="#000000"><div style="line-height:20px; font-size:18px;">Your Language Model May Think Too Rigidly: Achieving Reasoning Consistency with Symmetry-Enhanced Training</div></font></h5>
				<p style="line-height:20px;font-size:14px;">
					<span style="color: #000000"><strong>Yihang Yao</strong></span>, Zhepeng Cen, Miao Li,
					William Han, Yuyou Zhang, Emerson Liu, 
					Zuxin Liu, Chuang Gan, Ding Zhao
				</p> 
				<p style="line-height:10px;font-size:14px;color: #000000">
					ACL 2025 Findings
				</p> 
				<p style="line-height:20px;font-size:14px;color: #777777">
					TL;DR: MEND enhances LLM robustness by improving query symmetry awareness, boosting reasoning performance through structured dataset curation.
				<p style="line-height:10px;font-size:14px;color: #777777">
					<a href="https://arxiv.org/abs/2502.17800" target="_blank">Paper</a> 
				</p>
			</div>
		</div>
		
		<div class="row">
			<div id="OASIS" class="col-md-3">
				<a>
					<img class="img-responsive" src="./static/publication/OASIS_2.png" width="250px" height="160px" style="padding-top:30px">
				</a>
			</div>
			<div class="col-md-9" style="padding-top:30px">  
				<h5><font color="#000000"><div style="line-height:20px; font-size:18px;">OASIS: Conditional Distribution Shaping for Offline Safe Reinforcement Learning</div></font></h5>
				<p style="line-height:20px;font-size:14px;">
					<span style="color: #000000"><strong>Yihang Yao</strong></span>*, Zhepeng Cen*,
					Wenhao Ding, Haohong Lin, Shiqi Liu,
					Tingnan Zhang, Wenhao Yu, Ding Zhao
				</p> 
				<p style="line-height:10px;font-size:14px;color: #000000">
					NeurIPS 2024
				</p> 
				<p style="line-height:20px;font-size:14px;color: #777777">
					TL;DR: We investigate offline RL from a data-centric perspective and propose a diffusion model-based data generator to curate training datasets aligned with user preferences.
				</p> 
				<p style="line-height:10px;font-size:14px;color: #777777">
					<a href="https://openreview.net/pdf?id=3uDEmsf3Jf" target="_blank">Paper</a> / 
					<a href="https://sites.google.com/view/saferl-oasis" target="_blank">Website</a> /
					<a href="https://github.com/yihangyao/OASIS" target="_blank">Code</a>
				</p>
			</div>
		</div>

		<div class="row">
			<div id="FCSRL" class="col-md-3">
				<a>
					<img class="img-responsive" src="./static/publication/fcsrl.png" width="220px" height="160px" style="padding-top:20px; padding-left:40px">
				</a>
			</div>
			<div class="col-md-9" style="padding-top:30px">  
				<h5><font color="#000000"><div style="line-height:20px; font-size:18px;">Feasibility Consistent Representation Learning for Safe Reinforcement Learning</div></font></h5>
				<p style="line-height:20px;font-size:14px;">
					Zhepeng Cen, <span style="color: #000000"><strong>Yihang Yao</strong></span>, 
					Zuxin Liu, Ding Zhao
				</p> 
				<p style="line-height:10px;font-size:14px;color: #000000"> 
					ICML 2024
				</p> <!-- <span style="color: #038a10"><strong>(Spotlight)</strong></span></p> -->
				<p style="line-height:20px;font-size:14px;color: #777777">
					TL;DR: We introduce FCSRL, a framework that improves safety constraint estimation in RL through representation learning and self-supervised techniques.
				</p> 
				<p style="line-height:10px;font-size:14px;color: #777777">
					<a href="https://arxiv.org/pdf/2405.11718" target="_blank">Paper</a> /
					<a href="https://sites.google.com/view/fcsrl/home" target="_blank">Website</a> /
					<a href="https://github.com/czp16/FCSRL" target="_blank">Code</a>
				</p>
			</div>
		</div>

		<div class="row">
			<div id="GRADS" class="col-md-3">
				<a>
					<img class="img-responsive" src="./static/publication/GradS.png" width="200px" height="160px" style="padding-top:20px; padding-left:30px">
				</a>
			</div>
			<div class="col-md-9" style="padding-top:30px">  
				<h5><font color="#000000"><div style="line-height:20px; font-size:18px;">Gradient Shaping for Multi-Constraint Safe Reinforcement Learning</div></font></h5>
				<p style="line-height:20px;font-size:14px;">
					<span style="color: #000000"><strong>Yihang Yao</strong></span>, 
					Zuxin Liu, Zhepeng Cen, Peide Huang, Tingnan Zhang, Wenhao Yu, Ding Zhao
				</p> 
				<p style="line-height:10px;font-size:14px;color: #000000">
					L4DC 2024
				</p> 
				<p style="line-height:20px;font-size:14px;color: #777777">
					TL;DR: We introduce GradS, a gradient-based method for improving training efficiency in multi-constraint RL by manipulating gradients, optimizing both reward and constraint satisfaction.
				</p> 
				<p style="line-height:10px;font-size:14px;color: #777777">
					<a href="https://proceedings.mlr.press/v242/yao24a/yao24a.pdf" target="_blank">Paper</a> /
					<a href="https://sites.google.com/view/mc-grads/home" target="_blank">Website</a> /
					<a href="https://github.com/yihangyao/GradS" target="_blank">Code</a>
				</p>
			</div>
		</div>

		<div class="row">
			<div id="Versatile" class="col-md-3">
				<a>
					<img class="img-responsive" src="./static/publication/versatile.png" width="250px" height="150px" style="padding-top:50px">
				</a>
			</div>
			<div class="col-md-9" style="padding-top:30px">  
				<h5><font color="#000000"><div style="line-height:20px; font-size:18px;">Constraint-Conditioned Policy Optimization for Versatile Safe Reinforcement Learning</div></font></h5>
				<p style="line-height:20px;font-size:14px;">
					<span style="color: #000000"><strong>Yihang Yao</strong></span>*, Zuxin Liu*, 
					Zhepeng Cen, Jiacheng Zhu, Wenhao Yu, Tingnan Zhang, Ding Zhao
				</p> 
				<p style="line-height:10px;font-size:14px;color: #000000">
					NeurIPS 2023
				</p> 
				<p style="line-height:20px;font-size:14px;color: #777777">
					TL;DR: We introduce CCPO, a framework for versatile/adaptive safe RL that enables efficient training and zero-shot adaptation to varying safety constraints.
				</p> 
				<p style="line-height:10px;font-size:14px;color: #777777">
					<a href="https://arxiv.org/abs/2310.03718" target="_blank">Paper</a> 
				</p>
			</div>
		</div>

		<div class="row">
			<div id="Versatile" class="col-md-3">
				<a>
					<img class="img-responsive" src="./static/publication/CrashAgent.png" width="230px" height="200px" style="padding-top:20px">
				</a>
			</div>
			<div class="col-md-9" style="padding-top:30px">  
				<h5><font color="#000000"><div style="line-height:20px; font-size:18px;">CrashAgent: Crash Scenario Generation via Multi-modal Reasoning</div></font></h5>
				<p style="line-height:20px;font-size:14px;">
					Miao Li, Wenhao Ding, Haohong Lin, Yiqi Lyu, <span style="color: #000000"><strong>Yihang Yao</strong></span>, Yuyou Zhang, Ding Zhao
				</p> 
				<p style="line-height:10px;font-size:14px;color: #000000">
					2025
				</p> 
				<p style="line-height:20px;font-size:14px;color: #777777">
					TL;DR: CrashAgent, a multi-agent framework that leverages multi-modal large language models to convert real-world crash reports into diverse, executable simulation scenarios for training and evaluating autonomous driving in safety-critical situations.
				</p> 
				<p style="line-height:10px;font-size:14px;color: #777777">
					<a href="https://arxiv.org/abs/2505.18341" target="_blank">Paper</a> 
				</p>
			</div>
		</div>

		<div class="row">
			<div id="CDE" class="col-md-3">
				<a>
					<img class="img-responsive" src="./static/publication/cde.png" width="220px" height="180px" style="padding-top:30px; padding-left:30px">
				</a>
			</div>
			<div class="col-md-9" style="padding-top:30px">  
				<h5><font color="#000000"><div style="line-height:20px; font-size:18px;">Learning from Sparse Offline Datasets via Conservative Density Estimation</div></font></h5>
				<p style="line-height:20px;font-size:14px;">
					Zhepeng Cen,
					Zuxin Liu, Zitong Wang, 
					<span style="color: #000000"><strong>Yihang Yao</strong></span>, 
					Henry Lam, Ding Zhao
				</p> 
				<p style="line-height:10px;font-size:14px;color: #000000">
					ICLR 2024
				</p> <!-- <span style="color: #038a10"><strong>(Spotlight)</strong></span></p> -->
				<p style="line-height:20px;font-size:14px;color: #777777">
					TL;DR: We introduce CDE, a DICE-based method, which addresses OOD errors in offline RL, achieving SOTA results on the D4RL benchmark, particularly in sparse reward and low-data scenarios.
				</p> 
				<p style="line-height:10px;font-size:14px;color: #777777">
					<a href="https://arxiv.org/abs/2401.08819" target="_blank">Paper</a> /
					<a href="https://github.com/czp16/cde-offline-rl" target="_blank">Code</a> 
				</p>
			</div>
		</div>

		<div class="row">
			<div id="DSRL" class="col-md-3">
				<a>
					<img class="img-responsive" src="./static/publication/dsrl.png" width="250px" height="160px" style="padding-top:30px;">
				</a>
			</div>
			<div class="col-md-9" style="padding-top:30px">  
				<h5><font color="#000000"><div style="line-height:20px; font-size:18px;">Datasets and Benchmarks for Offline Safe Reinforcement Learning</div></font></h5>
				<p style="line-height:20px;font-size:14px;">
					Zuxin Liu*, Zijian Guo*, Haohong Lin, 
					<span style="color: #000000"><strong>Yihang Yao</strong></span>, 
					Jiacheng Zhu, Zhepeng Cen,
					Hanjiang Hu, Wenhao Yu, Tingnan Zhang, Jie Tan, Ding Zhao
				</p> 
				<p style="line-height:20px;font-size:14px;color: #000000">
					Journal of Data-centric Machine Learning Research (DMLR); 
					RSS 2023 Safe Autonomy Workshop <span style="color: #038a10"><strong>(Spotlight)</strong></span>
				</p> 
				<p style="line-height:20px;font-size:14px;color: #777777">
					TL;DR: We present a comprehensive benchmarking suite for offline safe RL, featuring expertly crafted safe policies, diverse datasets, and baseline implementations across 38 tasks, designed to accelerate the development and evaluation of safe RL algorithms in both training and deployment phases.
				</p> 
				<p style="line-height:10px;font-size:14px;color: #777777">
					<a href="https://arxiv.org/abs/2306.09303" target="_blank">Paper</a> /
					<a href="https://www.offline-saferl.org/" target="_blank">Website</a> /
					<a href="https://github.com/liuzuxin/osrl" target="_blank">Code (OSRL)</a> /
					<a href="https://github.com/liuzuxin/dsrl" target="_blank">Code (DSRL)</a> /
					<a href="https://github.com/liuzuxin/fsrl" target="_blank">Code (FSRL)</a>
				</p>
			</div>
		</div>
		


		<div class="row">
			<div id="CDT" class="col-md-3">
				<a>
					<img class="img-responsive" src="./static/publication/CDT_new.png" width="250px" height="140px" style="padding-top:40px">
				</a>
			</div>
			<div class="col-md-9" style="padding-top:30px">  
				<h5><font color="#000000"><div style="line-height:20px; font-size:18px;">Constrained Decision Transformer for Offline Safe Reinforcement Learning</div></font></h5>
				<p style="line-height:20px;font-size:14px;">
					 Zuxin Liu*, Zijian Guo*,
					 <span style="color: #000000"><strong>Yihang Yao</strong></span>,
					Zhepeng Cen, Wenhao Yu, Tingnan Zhang, Ding Zhao
				</p> 
				<p style="line-height:10px;font-size:14px;color: #000000">
					ICML 2023
				</p> <!-- <span style="color: #038a10"><strong>(Spotlight)</strong></span> --> 
				<p style="line-height:20px;font-size:14px;color: #777777">
					TL;DR: We propose CDT for offline safe RL, which leverages a multi-objective optimization approach to balance safety and task performance, achieving superior adaptability, robustness, and high-reward policies with zero-shot adaptation capabilities.
				</p> 
				<p style="line-height:10px;font-size:14px;color: #777777">
					<a href="https://arxiv.org/abs/2302.07351" target="_blank">Paper</a> /
					<a href="https://github.com/liuzuxin/dsrl" target="_blank">Code (DSRL)</a>
				</p>
			</div>
		</div>

		<!-- <div class="row">
			<div id="Safer" class="col-md-3">
				<a>
					<img class="img-responsive" src="./static/publication/SAFER.png" width="200px" height="180px" style="padding-top:20px; padding-left:40px">
				</a>
			</div>
			<div class="col-md-9" style="padding-top:30px">  
				<h5><font color="#000000"><div style="line-height:20px; font-size:18px;">Towards Robust and Safe Reinforcement Learning with Benign Off-policy Data</div></font></h5>
				<p style="line-height:20px;font-size:14px;">
					Zuxin Liu*, Zijian Guo*, Zhepeng Cen, Huan Zhang, 
					<span style="color: #000000"><strong>Yihang Yao</strong></span>,
					Hanjiang Hu, Ding Zhao
				</p> 
				<p style="line-height:10px;font-size:14px;color: #000000">
					ICML 2023
				</p> 
				<p style="line-height:20px;font-size:14px;color: #777777">
					TL;DR: We propose SAFER, a robust off-policy learning approach for safe RL that improves policy robustness without adversarial training.
				</p> 
				<p style="line-height:10px;font-size:14px;color: #777777">
					<a href="https://proceedings.mlr.press/v202/liu23l.html" target="_blank">Paper</a> 
				</p>
			</div>
		</div> -->
		
		<!-- <div class="row">
			<div id="SafeDE" class="col-md-3">
				<a>
					<img class="img-responsive" src="./static/publication/SafeDE.png" width="200px" height="180px" style="padding-top:20px; padding-left:10px">
				</a>
			</div>
			<div class="col-md-9" style="padding-top:30px">  
				<h5><font color="#000000"><div style="line-height:20px; font-size:18px;">Safe Control of Arbitrary Nonlinear Systems Using Dynamic Extension</div></font></h5>
				<p style="line-height:20px;font-size:14px;">
					<span style="color: #000000"><strong>Yihang Yao</strong></span>,
					Tianhao Wei, Changliu Liu
				</p> 
				<p style="line-height:20px;font-size:14px;color: #777777">
					TL;DR: We present a computationally efficient method for safe control in non-control-affine systems, using energy-function extensions and hyperparameter optimization to ensure safety and efficiency, with theoretical guarantees and numerical validation.
				</p> 
				<p style="line-height:10px;font-size:14px;color: #777777">
					<a href="https://arxiv.org/pdf/2111.04615v1.pdf" target="_blank">Paper</a>
				</p>
			</div>
		</div> -->

		<br>
		<br>
	</div>


	<!-- Honor -->
	<!-- <div class="container">
		<h5 id="Honors" style="padding-top: 75px; margin-top: -75px;">Honors and Awards</h5>
		<ul>
			<li></li>
		</ul>
		
		<br>
	</div> -->


	<!-- Services -->
	<div class="container">
		<h5 id="Service" style="padding-top: 75px; margin-top: -75px;">Services</h5>
		<ul>
			<li>
				<span class="title">Conference Reviewer: </span>
					NeurIPS 2023, 2024; ICLR 2024, 2025; ICML 2024; AISTATS 2025; AAAI 2024
			</li>
			<li>
				<span class="title">Teaching Assistance: </span>
					CMU 24-784 (2024 Spring)
			</li>
			<!-- <li>
				<span class="title">Mentoring: </span>
					Yuqing Wang (2023 Summer)
			</li> -->
		</ul>
	</div>

	<!-- Services -->
	<div class="container">
		<h5 id="Talks" style="padding-top: 75px; margin-top: -75px;">Talk</h5>
		<ul>
			<li>
				<span class="title">Invited speaker: </span>
				<span style="color: #000000"><strong>A Data-Centric Perspective on Offline Safe RL</strong></span>, UIUC Human-Centered Autonomy Lab (2024/09)
			</li>
			<!-- <li>
				<span class="title">Mentoring: </span>
					Yuqing Wang (2023 Summer)
			</li> -->
		</ul>
	</div>


	<!-- Footer -->
	<div class="container">
		<br><hr>
		<div class="row">
			<div class="col-md-3">
				<span style="float: right;">
					<!-- <script type="text/javascript" id="clustrmaps" src="//clustrmaps.com/map_v2.js?d=IGoCCI-YQyesyGmYw6nJSrD9ntAm0s9N4Q88ZLvI_E8&cl=ffffff&w=a"></script> -->
				</span>				
			</div>
		</div>
	</div>

	<!-- <script type="text/javascript" id="clustrmaps" src="//clustrmaps.com/map_v2.js?d=IGoCCI-YQyesyGmYw6nJSrD9ntAm0s9N4Q88ZLvI_E8&cl=ffffff&w=a"></script> -->

	<!-- ShowPubs choices -->
	<!-- <script>showPubs(0);</script>
	<script>var scroll = new SmoothScroll('a[href*="#"]', {speed: 1000});</script> -->


	<!-- Bootstrap core JavaScript -->
	<!-- Placed at the end of the document so the pages load faster -->
	<script src="https://code.jquery.com/jquery-3.2.1.slim.min.js" integrity="sha384-KJ3o2DKtIkvYIK3UENzmM7KCkRr/rE9/Qpg6aAZGJwFDMVNA/GpGFF93hXpG5KkN" crossorigin="anonymous"></script>
	<script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.11.0/umd/popper.min.js" integrity="sha384-b/U6ypiBEHpOf/4+1nzFpr53nxSS+GLCkfwBdFNTxtclqqenISfwAzpKaMNFNmj4" crossorigin="anonymous"></script>
	<script src="https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0-beta/js/bootstrap.min.js" integrity="sha384-h0AbiXch4ZDo7tp9hKZ4TsHbi047NrKGLO3SEJAg45jXxnGIfYzk4Si90RDIqNm1" crossorigin="anonymous"></script>
</body>

</html>